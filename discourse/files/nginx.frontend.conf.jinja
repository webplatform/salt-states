
#
# This is the PUBLIC virtual host for discuss.{{ tld }}
#
# Note that we call another NGINX virtual host, from the internal network,
# without SSL, and with a different name than the publicly exposed.
#
# Intention is that we can have multiple internal upstreams load-balanced
# by this very virtual host.
#
# ===========================================================================
#
# Managed by Salt Stack. Do NOT Edit manually!
# source: {{ source }}
#
# See also
#   - https://github.com/discourse/discourse/blob/master/config/nginx.sample.conf
#

{% if upstreams|count() >= 1 %}
upstream upstream_discourse {
{%- for b in upstreams %}
    server    {{ b }}:{{ upstream_port }};
{%- endfor %}
    keepalive 16;
}

# Let’s redirect to SSL, in case somebody tries to access the direct IP with
# host header.
server {
    listen      80;
    server_name discuss.{{ tld }} discusspolling.{{ tld }};
    include     common_params;
    return      301 https://$server_name$request_uri;
}

server {
    # Let’s only listen to SSL, Fastly will serve us,
    # and they dont support SPDY/HTTP2
    listen      443 ssl;
    server_name discuss.{{ tld }} discusspolling.{{ tld }};

    root    /var/www/html;
    include common_params;
    include ssl_params;

    ssl                 on;
    ssl_certificate     /etc/ssl/webplatform/public_wildcard_201509.pem;
    ssl_certificate_key /etc/ssl/webplatform/201509-fastly.key;

    # without weak etags we get zero benefit from etags on dynamically compressed content
    # further more etags are based on the file in nginx not sha of data
    # use dates, it solves the problem fine even cross server
    etag off;

    ###### Settings that arent part of defaults ######
    # maximum file upload size (keep up to date when changing the corresponding site setting)
    client_max_body_size 10m;
    gzip_vary on;
    gzip_min_length 1000;
    gzip_comp_level 5;
    gzip_types application/json text/css application/x-javascript application/javascript;
    ###### /Settings that arent part of defaults ######

    # Use internal Docker runner instance exposed port
    location / {
        proxy_pass             http://upstream_discourse;
        proxy_intercept_errors on;

        # Backend keepalive
        # ref: http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive
        proxy_http_version 1.1;
        proxy_set_header Connection "";
    }
}
{% else %}
# No upstreams found, let's not enable this service
{% endif %}
